{
 "metadata": {
  "name": "",
  "signature": "sha256:9d5d5ccc32457dbf6036cf86b88d016edf391529b2f4629ef25e85a3e73e4f91"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd ~/NetBeansProjects/ExpLosion/\n",
      "from notebooks.common_imports import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Volumes/LocalDataHD/m/mm/mmb28/NetBeansProjects/ExpLosion\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Does the classification evaluation framework work?\n",
      "What is the effect of adding uniform random noise to vectors? Can our experiments tell between a set of vectors and a corrupted version of the same vectors? To find out, add uniform random noise from $-n$ to $n$ (x axis) to all non-zero entries in a set of `word2vec` embeddings.\n",
      "     "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = {'vectors__unlabelled_percentage': 100,\n",
      "         'labelled': 'amazon_grouped-tagged',\n",
      "         'vectors__dimensionality': 100.0,\n",
      "         'decode_handler': 'SignifiedOnlyFeatureHandler',\n",
      "         'vectors__composer': 'Add',\n",
      "         'vectors__rep': 0, \n",
      "         'k': 3,\n",
      "         'vectors__unlabelled': 'gigaw',\n",
      "         'vectors__algorithm': 'word2vec',\n",
      "         'document_features': 'AN_NN'}\n",
      "e = Experiment.objects.filter(**d).order_by('noise').values_list('id', flat=True)\n",
      "from thesisgenerator.utils.output_utils import get_scores, get_cv_fold_count\n",
      "import numpy as np\n",
      "cv_folds = get_cv_fold_count(e)\n",
      "scores, folds, _ = get_scores(e)\n",
      "raw_names = Experiment.objects.filter(id__in=e).order_by('noise').values_list('noise', flat=True)\n",
      "print([type(x) for x in raw_names])\n",
      "# calculate significance\n",
      "from itertools import tee\n",
      "from gui.user_code import get_demsar_params\n",
      "def pairwise(iterable):\n",
      "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
      "    a, b = tee(iterable)\n",
      "    next(b, None)\n",
      "    return zip(a, b)\n",
      "\n",
      "for i, (e1, e2) in enumerate(pairwise(e)):\n",
      "    t, _, _ = get_demsar_params([e1, e2], name_format=['id'])\n",
      "    if t.significant[0] == 'True':\n",
      "        # significant difference exists\n",
      "        raw_names[i] = '%.1f*'%raw_names[i]\n",
      "\n",
      "names = np.repeat(raw_names, cv_folds)\n",
      "df = pd.DataFrame(dict(Noise=names, F1=scores, folds=folds))\n",
      "ax = sns.factorplot('Noise', 'F1', data=df, kind='bar');\n",
      "ax.set_xticklabels(rotation=90);\n",
      "\n",
      "# random baseline for comparison\n",
      "rand = Experiment.objects.get(vectors__algorithm='random_vect', labelled='amazon_grouped-tagged').id\n",
      "score, score_std = Results.objects.get(id=rand, \n",
      "                                          classifier='MultinomialNB').get_performance_info('macrof1')\n",
      "plt.hlines(score, -100, 100)\n",
      "plt.savefig('plot-noise-gigaword-add.pdf', format='pdf', dpi=300, bbox_inches='tight', pad_inches=0.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[<class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]\n",
        "running performance query for experiments [27, 101]\n",
        "Running significance for experiments [27, 101]\n",
        "running performance query for experiments [101, 102]\n",
        "Running significance for experiments [101, 102]\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "'ValuesListQuerySet' object does not support item assignment",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-5-4034b8c81ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignificant\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'True'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# significant difference exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mraw_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%.1f*'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mraw_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: 'ValuesListQuerySet' object does not support item assignment"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}